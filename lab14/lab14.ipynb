{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphiz\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.processing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inlines\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import explain_weights, show_weights\n",
    "from yellowbrick import ROCAuc\n",
    "from yellowbrick.classifier import ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imported all libraries successfully\")\n",
    "print(os.listdir(\"Phys\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_N_REPEATS = 5\n",
    "BINS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Vlagun_Phys_Years3.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the dataset\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df.Years,\".\")\n",
    "plt.title(\"Years\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.countplot(data=df, x=\"Years\")\n",
    "ax.set_title('Seaborn countplot of Years within the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,4,figsize=(15,15))\n",
    "sns.set(style=\"whitegrid\", palette=\"Set3\", color_codes=True)\n",
    "sns.boxplot(y='PSU', x='Years', data=df, orient='v', ax=axes[0,0])\n",
    "sns.boxplot(y='O2', x='Years', data=df, orient='v', ax=axes[0,1])\n",
    "sns.boxplot(y='temp', x='Years', data=df, orient='v', ax=axes[0,2])\n",
    "sns.boxplot(y='SS', x='Years', data=df, orient='v', ax=axes[0,3])\n",
    "sns.boxplot(y='DOC', x='Years', data=df, orient='v', ax=axes[1,0])\n",
    "sns.boxplot(y='TPOC', x='Years', data=df, orient='v', ax=axes[1,1])\n",
    "sns.boxplot(y='Windspeedinsitu', x='Years', data=df, orient='v', ax=axes[1,2])\n",
    "sns.boxplot(y='Depth', x='Years', data=df, orient='v', ax=axes[1,3])\n",
    "\n",
    "f.subplots_adjust(left=0.08, right=0.98, top=0.9, bottom=0.05, hspace=0.4, wspace=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy(deep=True)\n",
    "df_copy[['PSU', 'O2', 'temp', 'SS', 'DOC', 'TPOC', 'Windspeedinsitu', 'Depth']] = StandardScaler().fit_transform(df_copy[['PSU', 'O2', 'temp', 'SS', 'DOC', 'TPOC', 'Windspeedinsitu', 'Depth']])\n",
    "print('Number of zero entries in each attribute:')\n",
    "print(df_copy.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((15,15)))\n",
    "corr=df_copy.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot=True, cmap=plt.cm.Reds)\n",
    "plt.title('Correlation Heatmap', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.pairplot(data=df_copy, hue='Years', diag_kind='kde', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8].values\n",
    "y = df.iloc[:,8].values\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = DummyClassifier(strategy='most_frequent')\n",
    "dum.fit(X_train, y_train)\n",
    "score = dum.score(X_test, y_test)\n",
    "print(\"Dummy Classifier accuracy: %.2f%%\" % (score*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = 'most_frequent'\n",
    "scores = cross_val_score(dum, X,y, cv=RepeatedKFold(n_repeats=CV_N_REPEATS, n_splits=10), scoring=None)\n",
    "scores_dummy = scores.copy()\n",
    "score_line = 'Scores (Accuracy) mean={0:.2f} +/- {1:.2f}'.format(scores.mean(), scores.std())\n",
    "plt.figure(figsize=(7,7))\n",
    "fig, ax = plt.subplots()\n",
    "pd.Series(scores).hist(ax=ax, bins=BINS)\n",
    "ax.set_title(f\"RepeatedKFold ({len(scores)} folds) with DummyClassifier ({strategy}) \\n + {score_line}\")\n",
    "ax.set_xlabel('Score')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree_graph(model, columns, class_names):\n",
    "    dot_data = export_graphviz(model, feature_names=columns, class_names=class_names)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(Y_pred, Y_test):\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(Y_pred, Y_test)\n",
    "    sns.heatmap(cm,annot=True, fmt='g')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=1, max_depth=3)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt_scores = cross_val_score(dt, X,y, cv=RepeatedStratifiedKFold(n_repeats=CV_N_REPEATS))\n",
    "print(f\"Accuracy mean = {dt_scores.mean()} +/- {dt_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(n_estimators = 100, oob_score=True, random_state=1)\n",
    "bag=bag.fit(X_train, y_train)\n",
    "bag_scores = cross_val_score(bag, X,y, cv=RepeatedStratifiedKFold(n_repeats=CV_N_REPEATS))\n",
    "print(f\"Accuracy mean = {bag_scores.mean()} +/- {bag_scores.std()}\")\n",
    "print(\"Out of bag score = %.2f\" % bag.oob_score_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_estimators = 100\n",
    "rf = RandomForestClassifier(n_estimators=num_estimators, random_state=1)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf_scores = rf.score(X_test, y_test)\n",
    "print(\"Random Forest accuracy: %.2f%%\" % (rf_scores*100.0))\n",
    "y_pred = rf.predict(X_test)\n",
    "confusion_mat(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values\n",
    "show_weights(rf, feature_names= feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf, X,y, cv=RepeatedStratifiedKFold(n_repeats=CV_N_REPEATS))\n",
    "scores_rf = scores.copy()\n",
    "print(f\"Scores mean = {scores.mean()}, stddev = {scores.std()}\")\n",
    "score_line = 'Scores (Accuracy) mean={0:.2f} +/- {1:.2f}'.format(scores.mean(), scores.std())\n",
    "plt.figure(figsize=(7,7))\n",
    "fig, ax = plt.subplots()\n",
    "pd.Series(scores).hist(ax=ax, bins=BINS)\n",
    "ax.set_title(f\"RepeatedKFold ({len(scores)} folds) with RandomForestClassifier + {score_line}\")\n",
    "ax.set_xlabel('Score')\n",
    "ax.set_ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "params={'n_estimators':[500], \"learning_rate\": 0.01, \"max_depth\": 5, \"loss\":'deviance'}\n",
    "gbm = GradientBoostingClassifier(**params)\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "for i, y_pred in enumerate(gbm.staged_predict(X_test)):\n",
    "    test_score[i] = gbm.loss_(y_test, y_pred)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('GBM Deviance w.r.t Number of Estimators')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, gbm.train_score_, 'b-',\n",
    "            label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "            label='Test Set Deviance')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"n_estimators\": 100, \"max_depth\": 4, \"learning_rate\": 0.01, \"loss\": 'deviance'}\n",
    "gbm = GradientBoostingClassifier(**params)\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "gbm_score = accuracy_score(y_test, y_pred)\n",
    "print(\"GBM accuracy: %.2f%%\" % (gbm_score*100.0))\n",
    "confusion_mat(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = gbm.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, df.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance, to_graphviz\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.8, 'subsample':1, 'objective':'binary:logistic', 'n_estimators':1000, 'learning_rate':0.001}\n",
    "xgb = XGBClassifier(**param)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "xgb_score = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB accuracy: %.2f%%\" % (xgb_score*100.0))\n",
    "confusion_mat(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_importance(xgb, title='Feature importance from XGboost model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocesing import OneHotEncoder, LabEncoder\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Vlagun_Phys_Year3.csv')\n",
    "data.dropna(inplace=True)\n",
    "X = pd.get_dummies(data)\n",
    "X.drop(['Years'], inplace=True, axis=1)\n",
    "y = data['Years']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8].values\n",
    "y = df.iloc[:,8].values\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators = 1000, max_depth=10, learning_rate=0.001)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "model_score = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB accuracy: %.2f%%\" % (model_score*100.0))\n",
    "confusion_mat(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "shap.force_plot(explainer.expected_value[i], shap_values[i], features = X.iloc[i], features_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 109\n",
    "shap.force_plot(explainer.expected_value[i], shap_values[i], features = X.iloc[i], features_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features = X, feature_names = X.columns, show=False)\n",
    "plt.savefig('plot.png', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features = X, feature_names = X.columns, show=False, plot_type = 'bar')\n",
    "plt.savefig('plot2.png', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('Windspeedinsitu', shap_values, features = X, interaction_index = 'DOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[:121,:], show=False, features=X.iloc[:121,:])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
